<!DOCTYPE html>

<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml"><head>
<meta charset="utf-8"/>
<meta content="quarto-1.4.315" name="generator"/>
<meta content="width=device-width, initial-scale=1.0, user-scalable=yes" name="viewport"/>
<meta content="Steve J. Bickley, Ho Fai Chan, Bang Dao, Benno Torgler, Son Tran" name="author"/>
<meta content="Natural Conversation, Social Science, Social AI, Large Language Models, Augmented Language Models, Alignment Research, Natural Conversation, Experimental Method" name="keywords"/>
<meta content="Panalogy Lab Technical Report 2023-001" name="description"/>
<title>her: a platform to explore the possibility of natural conversational AI</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>
<script src="her_files/libs/clipboard/clipboard.min.js"></script>
<script src="her_files/libs/quarto-html/quarto.js"></script>
<script src="her_files/libs/quarto-html/popper.min.js"></script>
<script src="her_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="her_files/libs/quarto-html/anchor.min.js"></script>
<link href="her_files/libs/quarto-html/tippy.css" rel="stylesheet"/>
<link href="her_files/libs/quarto-html/quarto-syntax-highlighting.css" id="quarto-text-highlighting-styles" rel="stylesheet"/>
<script src="her_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="her_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet"/>
<link data-mode="light" href="her_files/libs/bootstrap/bootstrap.min.css" id="quarto-bootstrap" rel="stylesheet"/>
<style>html{ scroll-behavior: smooth; }</style>
</head>
<body>
<header class="quarto-title-block default toc-left page-columns page-full" id="title-block-header">
<div class="quarto-title-banner page-columns page-full">
<div class="quarto-title column-body">
<h1 class="title">her: a platform to explore the possibility of natural conversational AI</h1>
<div>
<div class="description">
          Panalogy Lab Technical Report 2023-001
        </div>
</div>
</div>
</div>
<div class="quarto-title-meta-author">
<div class="quarto-title-meta-heading">Author</div>
<div class="quarto-title-meta-heading">Affiliation</div>
<div class="quarto-title-meta-contents">
<p class="author">Steve J. Bickley, Ho Fai Chan, Bang Dao, Benno Torgler, Son Tran <a class="quarto-title-author-email" href="mailto:steven.bickley@panalogy-lab.com"><i class="bi bi-envelope"></i></a> </p>
</div>
<div class="quarto-title-meta-contents">
<p class="affiliation">
<a href="https://panalogy-lab.com">
              Panalogy Lab
              </a>
</p>
</div>
</div>
<div class="quarto-title-meta">
<div>
<div class="quarto-title-meta-heading">Published</div>
<div class="quarto-title-meta-contents">
<p class="date">24.10.2023</p>
</div>
</div>
</div>
<div>
<div class="abstract">
<div class="block-title">Abstract</div>
<p>Our platform, “her”, aims to advance the rapidly evolving field of natural conversational Artificial Intelligence (AI) by integrating the emergent capabilities of Augmented Language Models (ALMs) with a dual voice and text modality.</p>
<p>In essence, natural conversational AI is about designing AI systems to interact with humans in a way that feels “natural”. This includes understanding and generating human language, recognizing speech, interpreting context, resolving ambiguity, and even having an understanding and expression of emotions and empathy. The ultimate goal of natural conversational AI is to create artificial agents that can converse with a human just like another human would, making human-computer interactions as seamless and intuitive as possible, and opening up prospects for long-lived human-AI social interactions.</p>
<p>Through “her”, we aim to comprehend the underlying principles and mechanisms that make AI interactions feel more natural and intuitive to humans. We are keen on dissecting the factors that contribute to the perceived “naturalness” of a conversation with AI and developing metrics to quantitatively evaluate this quality over time.</p>
<p>Harnessing the power of state-of-the-art (SOTA) AI models, we have integrated advanced techniques and technologies into a unified platform capable of engaging in natural conversations. This innovative system will not only advance our understanding of AI-human interactions but also bring practical solutions to various sectors.</p>
<p>Key applications for our research lie in the realms of (among others) education and entertainment. In education, this platform could serve as an intelligent tutor providing personalized assistance, while in entertainment, it could revolutionize how audiences interact with digital content. This project, therefore, holds substantial promise in fostering a more seamless and dynamic interaction between AI and human users, propelling us further into the age of natural conversational AI.</p>
</div>
</div>
<div>
<div class="keywords">
<div class="block-title">Keywords</div>
<p>Natural Conversation, Social Science, Social AI, Large Language Models, Augmented Language Models, Alignment Research, Natural Conversation, Experimental Method</p>
</div>
</div>
</header><div class="page-columns page-rows-contents page-layout-article toc-left" id="quarto-content">
<div class="sidebar toc-left" id="quarto-sidebar-toc-left">
<nav class="toc-active" id="TOC" role="doc-toc">
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a class="nav-link active" data-scroll-target="#motivation" href="#motivation" id="toc-motivation">Motivation</a></li>
<li><a class="nav-link" data-scroll-target="#sec-background" href="#sec-background" id="toc-sec-background">Background</a></li>
<li><a class="nav-link" data-scroll-target="#sec-paltform-design-and-features" href="#sec-paltform-design-and-features" id="toc-sec-paltform-design-and-features">Platform Design and Features</a></li>
<li><a class="nav-link" data-scroll-target="#sec-limitations-and-future-possibilities" href="#sec-limitations-and-future-possibilities" id="toc-sec-limitations-and-future-possibilities">Limitations and Future possibilities</a></li>
<li><a class="nav-link" data-scroll-target="#references" href="#references" id="toc-references"><strong>References</strong></a></li>
</ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="her_files/her.pdf" target="_blank"><i class="bi bi-file-pdf"></i>PDF</a></li><li><a href="her_files/her.docx"><i class="bi bi-file-word"></i>MS Word</a></li></ul></div></nav>
</div>
<div class="sidebar margin-sidebar" id="quarto-margin-sidebar">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">
<div style="page-break-after: always;"></div>
<section class="level1" id="motivation">
<h1>Motivation</h1>
<p>We built “her” with the following motivations in mind:</p>
<ul>
<li><p>Language models such as GPT-4, Bard, Claude, etc. are touted as a pathway to AGI, and the ultimate test of AGI is the capability to make complex decisions involving interactions with humans and other artifacts in complex social settings (not just writing a poem or making a video). Making these kinds of complex social decisions, e.g. making friends, choosing spouses, pursuing a degree, trusting an AI system, telling a lie, etc., is what humans do every day in their societies.</p></li>
<li><p>Thus, being able to make complex social decisions is a crucial test of AGI, and every social decision seems to start and end with a natural conversation. Natural conversations create decision premises that underpin decision processes. Thus, being able to engage in natural conversations plays a key role in designing AGI. Here, we define natural conversations are conversations that include, but not limited to, these elements: critical yet constructive and creative engagement, adaptive spontaneity, multi-modal and adaptive conversation style, evolving identity and perception formation, contextual understanding and expression of emotions, multi-level reflection, dynamic memories, grounded decision-making knowledge, and understanding of uncertainty.</p></li>
<li><p>“her” is a platform to study and design AI system capable of engaging in natural conversations with humans. The platform was designed to explore to what extent we can address the limits of current LMs and their hard-coded prompt-engineering variants in terms of engaging in natural conversations. These models inherently lack most elements of naturalness when engaging in complex conversations. Our research explores ways to address this inherent limitation by extending the models with additional layers that learn to develop the elements of naturalness over time, through experience gained from past conversations.</p></li>
</ul>
</section>
<section class="level1" id="sec-background">
<h1>Background</h1>
<p>The development of Large Language Models (LLMs) marks a significant milestone for conversational AI. These models, which leverage sophisticated algorithms to understand and generate human-like text, have redefined our ability to create systems capable of engaging in meaningful dialogues. Particularly as they become increasingly convincing and capable through augmentations (i.e., Augmented Language Models or ALMs) via techniques like in-context learning and chain-of-thought prompting (Lee et al., n.d.), external memory, and the integration of other and multiple modalities (e.g., sound, visual). See <span class="citation" data-cites="mialon_augmented_2023">Mialon et al. (<a href="#ref-mialon_augmented_2023" role="doc-biblioref">2023</a>)</span> for a seminal review on ALMs. The increased complexity and fluency of these ALMs have brought us one step closer to the realization of more natural, human-like conversations with machines.</p>
<p>Yet, it’s important to differentiate between a conversation and a ‘natural’ conversation. While a conversation may involve a simple exchange of information (e.g., question-answering, a recommendation), a ‘natural’ conversation is characterized by adaptive spontaneity, critical and constructive engagement, context-awareness, emotional understanding, contextual memories, grounded knowledge, and the ability to manage the flow of dialogue, and often intertwined with complex elements such as humor, idioms, cultural nuances, and ambiguity.</p>
<p>Regarding conversational agents, findings from certain human-computer interaction (HCI) studies indicate that humans often prioritize the transactional aspects of conversation, such as task completion and goal attainment, over the more social, interactive elements <span class="citation" data-cites="clark_what_2019">Clark et al. (<a href="#ref-clark_what_2019" role="doc-biblioref">2019</a>)</span> . This mirrors the conversational requirements with strangers or casual acquaintances. However, it’s worth noting that such a focus may shift based on factors like user characteristics <span class="citation" data-cites="ahlemann_user-specific_2021">Riefle &amp; Benz (<a href="#ref-ahlemann_user-specific_2021" role="doc-biblioref">2021</a>)</span> and the specific context of use <span class="citation" data-cites="rheu_systematic_2021">Rheu et al. (<a href="#ref-rheu_systematic_2021" role="doc-biblioref">2021</a>)</span>. Intriguingly, marketing research presents a more favorable view regarding the benefits of more natural conversational agents <span class="citation" data-cites="mariani_artificial_2023">Mariani et al. (<a href="#ref-mariani_artificial_2023" role="doc-biblioref">2023</a>)</span>. This optimism could suggest the significant value that consumers place on conversational AI now and into the future.</p>
<p><span class="citation" data-cites="clark_what_2019">Clark et al. (<a href="#ref-clark_what_2019" role="doc-biblioref">2019</a>)</span> posed an intriguing question: what makes a good conversation? According to their study, humans value mutual understanding, trustworthiness, active listening, and humor in their conversations, but these traits’ desirability can differ across various types of human-human relationships. When it comes to human-agent interactions, these tend to be more transactional, utilitarian, and one-sided. However, sensitivity to the context of interaction, understanding of the conversation type required, and the underlying interaction purpose remain vital (p. 475). It is also worth noting that social functions of conversation play a critical role in establishing common ground, trust, and a sense of connection among participants. So, both transitional and social talk are important, and whilst serving distinct purposes, they frequently intersect in the context of natural conversations.</p>
<p>Why does natural conversation matter? The more ‘natural’ an AI’s conversational capabilities are, the more intuitive, engaging, and satisfying the user’s experience becomes. This seamless interaction fosters trust and understanding, reduces frustration, and increases the chances of successful communication.</p>
<p>So, why AI? AI’s unique attributes make it an ideal candidate for facilitating natural conversation. Its limitless patience enables it to handle complex interactions without exhaustion. Its vast knowledge base allows it to provide accurate information across an array of topics. Its capability to simulate compassion can make conversations more comforting. Its constant availability ensures round-the-clock assistance, and its universal application means it can be customized to serve diverse needs across different cultures, languages, and domains.</p>
<p>At Panalogy Lab, we recognize that we are at the precipice of a new era where AI systems can function as enduring agents capable of making complex decisions, while interacting with humans and other entities in real-world social contexts. We acknowledge the monumental challenge of aligning the decision-making behaviors of these social AI systems with the evolving intentions and values of human society, an area whose complexity we are still endeavoring to fully comprehend. Our approach, however, is firmly rooted in this challenge. We believe that by infusing AI systems with social and emotional intelligence, we can create agents that can more effectively understand and mimic human conversational patterns. Through this, we aim to revolutionize the way humans interact with technology, pushing the boundaries of conversational AI and striving towards a future where AI not only understands our language but also the complex social fabric in which it is embedded.</p>
</section>
<section class="level1" id="sec-paltform-design-and-features">
<h1>Platform Design and Features</h1>
<p>The patlform’s design process is guided by the following principles.</p>
<p><strong>Scientific focus on natural conversation:</strong> the platform should be able to create an authentic feeling of having face-to-face natural conversations. Here, we take a scientific approach to identifying key elements of what make a conversation natural by carefully reviewing existing ideas in relevant literature and creating new constructs based on our own insights. These elements include, but not limited to, these elements: critical yet constructive and creative engagement, adaptive spontaneity, multi-modal and adaptive conversation style, evolving perception formation, contextual understanding and expression of emotions, multi-level reflection, dynamic memories, grounded perception and decision-making knowledge, and understanding of uncertainty. With these elements identified, we collect conversational data and transformed them into parameters that can be used by scientific methods to evaluate the naturalness of a conversation.</p>
<p><strong>Evolving and grounded companionship:</strong> we started with the premise that natural conversations, if sustained over time, may result in an emergent companionship between human users and the platform. This companionship, however, must satisfy two criteria. First, it must be a result of learning from conversational evolution rather than instructions embedded in rigidly engineered prompt. Second, the platform’s operations should be grounded in the sense that LMs do not actually “understand” what a conversation means in the best possible way and that they should not be instructed to “pretend” to assume a human character. Prompt engineering is the most obvious evidence showing that LMs lacks the kind of nuance “understanding” that humans have: a slightly rephrased can result in a significant different outcome. Our goal is to see whether, with evolution based on context learning based on our scientific framework, a new kind of companionship between humans and AI systems can emerge.</p>
<p><strong>Ease of interaction :</strong> The goal is to make users’ interaction with the platform as intuitive and simple as possible while making conversations flow smoothly. Since computers and humans have different ways of initiating and engaging in a conversation, especially the use of sensory elements, achieving this goal is an on-going process. The best solution is likely a compromise between what can be made possible by existing software and hardware technologies and how much users find the platform useful.</p>
<p>Based on these principles, “her” was built with several components as shown in Figure 1.</p>
<div class="quarto-figure quarto-figure-center anchored" id="platform-components">
<figure class="figure">
<p><img alt="platform design" class="img-fluid figure-img" src="her_files/design.png"/></p>
<figcaption class="figure-caption">Key components of the platform design</figcaption>
</figure>
</div>
<p>The platform’s components were designed to enhance user interaction and facilitate research.</p>
<p><strong>Frontend Interface:</strong> The interface serves as the gateway for users to interact with the platform. It provides users with simple voice and text input together with basic parameter configurations and document upload. The interface is designed to be user-friendly and intuitive, minimizing the learning curve for new users.</p>
<p><strong>Databases:</strong> user credential database was separated from per-user conversation data, enabling optimization of platform’s operations. The conversation data includes on-the-fly records of each message exchange in each conversation, context learning data, and relevant data. One important feature of this data is a set of vectors that capture various context of each conversation, creating a memory foundation for the platform.</p>
<p><strong>Backend interface:</strong> This is where a conversation request is started and ended. The backend interface is responsible for authenticating users, processing input data and sending relevant responses to the frontend listener. It executes these tasks through appropriate interface calls to the user credential database and the conversation component.</p>
<p><strong>Conversation:</strong> This is where a conversation process starts and ends. The conversation component is responsible for initializing per-user conversation context using historical conversation data, processing messages and document from users, performing conversation prompt parameterization , initiating function calls and context learning, and sending appropriate requests to LMs. On important feature of this component is the parameterization of prompts for LMs. Instead of using static prompts, the platform utilized parameterized prompts with the parameters being replaced with appropriate value and linguistic constructs learned from the latest conversation with the user. This on-the-fly prompt construction enables adaptive spontaneity and conversation style that usually lead to novel surprises. The conversation component serves as a conduit, ensuring efficient and correct data flow within the platform. It also internalizes the complexity of prompt engineering and related operations needed to ensure that the LLMs behave consistently in term of the structure of their response.</p>
<p><strong>Context learning:</strong> This component performs background learning tasks that enable the platform to observe conversations and extract insights from which future conversations will incorporate. These insights are gradually collated into layers of reflection enabling evolving perception of self and the world experienced through conversations. The insights will be incorporated into future conversations as on-the-fly parameters.</p>
<p><strong>Function calls:</strong> Function calls are unique features of OpenAI’s GPT class of models. They augment a LM with the capability to return a function call encoded in a JSON format that can be parsed to invoked customized functions that perform tasks that make the LM more factual and powerful. Besides providing LMs with a coherent way to generate grounded and up-to-date content unavailable in the stock models, function calls can be used, together with context learning and on-the-fly parameterization, to perform complex tasks such as contextual recall and learning to perceive human experience through conversations. While function calls are still an experimental features and often limited to simple tasks dealing with simple data structure, out platform has been equipped with function calls that can perform complex tasks such as reflection in a reliable way.</p>
<p>As a result of our platform design choices, the following features have been developed:</p>
<ul>
<li><p>Automatic switching between languages is more reliable and natural, and this applies to both text and voice responses.</p></li>
<li><p>‘her’ can vary speaking rate and pitch to better express emotions that are adaptive to the conversational context.</p></li>
<li><p>‘her’ has both short-term and long-term memories to store conversational context.</p></li>
<li><p>‘her’ can gradually make observations about your character, enabling adaptive conversations. ‘her’ also makes observations of ‘her’ self. You can test this capability by asking “her” to tell you what ‘her’ thinks of you after chatting a while. The observations can be critical from time to time, and they are done in a way to minimize the impact on response speed.</p></li>
<li><p>‘her’ also gradually learn how to perceive the world through context learning and on-the-fly prompt parameterization.</p></li>
<li><p>Gradually, ‘her’ will develop a sense of itself and a sense of your character in a conversational context. This is done by gradually observing . In other words, ‘her’ will develop a distinct personality and conversational style that are unique to you. This personality is a product of conversational evolution, not hard-coded character.</p></li>
<li><p>Recalling memories is done via a function call. This function is triggered automatically when the GPT model detects contextual signal indicating that the user wants to talk about things that was or happened in the past.</p></li>
<li><p>‘her’ will reflect on or learn how to perceive an emotional experience when the user talks about emotions or feelings. This is also done automatically via function call.</p></li>
<li><p>The user can upload a document and ‘her’ will read, analyze, and answer the user’s queries when there are appropriate signals. This is also done automatically via a function call whenever the user mentions document-related content. Otherwise, the document content will be ignored.</p></li>
<li><p>The user can mention a website address, such as panalogy-lab.com, and ‘her’ will automatically create a query inferred from the user message, read the website content, and respond to the query. This is also done automatically via a function call.</p></li>
<li><p>Conversation data is now network-ready for network construction and analysis. Moving forward, we plan to build a reinforcement learning agent operating on network measures capturing systematic meaning of naturalness. This will enable ‘her’ to be adaptive on another level.</p></li>
<li><p>Overall, an interesting feature of this update is that ‘her’ will from time to time display emergent behaviors by using function calls in a ways never expected before.</p></li>
</ul>
</section>
<section class="level1" id="sec-limitations-and-future-possibilities">
<h1>Limitations and Future possibilities</h1>
<p>There are a number of challenges and implications in the field of conversational AI that need to be acknowledged. As highlighted by <span class="citation" data-cites="chen_evaluating_2021">Chen et al. (<a href="#ref-chen_evaluating_2021" role="doc-biblioref">2021</a>)</span>, these include aspects of overreliance, misalignment, bias and representation, economic and labour market impacts, security concerns, environmental implications, and legal ramifications. These aspects, drawn from the early work of <span class="citation" data-cites="leveson_improving_2019">Leveson (<a href="#ref-leveson_improving_2019" role="doc-biblioref">2019</a>)</span> on refining risk matrices and calibration models of likelihood, also broadly apply to other generative interfaces, including conversational and companion agents.</p>
<p>While there are limitations, the field also presents immense possibilities for the future. <span class="citation" data-cites="jokinen_is_2017">Moore (<a href="#ref-jokinen_is_2017" role="doc-biblioref">2017</a>)</span> intriguingly suggests that we explore the characteristics and attributes of various other human-agent interactions, such as those between native and non-native speakers, adults and children, or humans and animals. The insights gained from this process could be integrated into “her”, helping us develop more sophisticated and nuanced AI models that cater to a diverse range of conversational dynamics and role-play expectations.</p>
<p>In addition to this, <span class="citation" data-cites="feine_taxonomy_2019">Feine et al. (<a href="#ref-feine_taxonomy_2019" role="doc-biblioref">2019</a>)</span> propose a taxonomy of social cues for conversational agents encompassing verbal (content, style), visual (kinesics, proxemics, agent appearance, CMC), auditory (voice qualities, vocalization), invisible (chronemics, haptics) cues. This taxonomy can be instrumental in enhancing the ALM’s capacity for social behavior and responsiveness. By incorporating these social cues into our AI system, we could provide a more immersive, interactive, and satisfying conversational experience for users, making AI interactions feel more natural and engaging.</p>
<p>Conversational agents through ALMs have also laid the groundwork for conversational recommender systems <span class="citation" data-cites="friedman_leveraging_2023">Friedman et al. (<a href="#ref-friedman_leveraging_2023" role="doc-biblioref">2023</a>)</span>, as embodied in our <a href="https://panalogy-lab.com/research.html">“Expert Recommender”</a> product. Such systems hold potential for revolutionizing how users receive personalized recommendations, making the process more interactive and intuitive.</p>
<p>The basic framework provided by <span class="citation" data-cites="alnefaie_overview_2021">Alnefaie et al. (<a href="#ref-alnefaie_overview_2021" role="doc-biblioref">2021</a>)</span> also presents a valuable direction for our project. Their classification of conversational agents, based on their roles (general purpose vs task specific) and interaction style (menu-based vs voice/text-based or other generative or communicative medium), opens up a multitude of potential use cases. By leveraging this classification in the “her” project, we can design and customize our conversational AI to cater to a variety of sectors, such as education, healthcare, marketing, customer service, and entertainment, further expanding the project’s scope and impact.</p>
<p>The future of the “her” project is also promising when considering the potential intersection and integration of theories like the Technology Acceptance Model (TAM), with concepts/paradigms such as Embodied Conversational Agents (ECA), Computers are Social Actors (CASA), Social Signal Processing (SSP), and Intelligence Amplification (AI). These avenues of research provide innovative and interdisciplinary ways to enhance and evolve the design and application of conversational agents. By exploring these domains and incorporating their principles into our project, we can continually improve the “her” platform, ensuring its relevance and effectiveness in the rapidly progressing world of conversational AI.</p>
<div style="page-break-after: always;"></div>
</section>
<section class="level1 unnumbered" id="references">
<h1 class="unnumbered"><strong>References</strong></h1>
<div class="references csl-bib-body hanging-indent" data-line-spacing="2" id="refs" role="list">
<div class="csl-entry" id="ref-alnefaie_overview_2021" role="listitem">
Alnefaie, A., Singh, S., Kocaballi, B., &amp; Prasad, M. (2021). An overview of conversational agent: Applications, challenges and future directions: <em>Proceedings of the 17th International Conference on Web Information Systems and Technologies</em>, 388–396. <a href="https://doi.org/10.5220/0010708600003058">https://doi.org/10.5220/0010708600003058</a>
</div>
<div class="csl-entry" id="ref-chen_evaluating_2021" role="listitem">
Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. de O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., … Zaremba, W. (2021). <em>Evaluating large language models trained on code</em> (<span>arXiv</span>:2107.03374). <span>arXiv</span>. <a href="https://doi.org/10.48550/arXiv.2107.03374">https://doi.org/10.48550/arXiv.2107.03374</a>
</div>
<div class="csl-entry" id="ref-clark_what_2019" role="listitem">
Clark, L., Pantidi, N., Cooney, O., Doyle, P., Garaialde, D., Edwards, J., Spillane, B., Gilmartin, E., Murad, C., Munteanu, C., Wade, V., &amp; Cowan, B. R. (2019). What makes a good conversation?: Challenges in designing truly conversational agents. <em>Proceedings of the 2019 <span>CHI</span> Conference on Human Factors in Computing Systems</em>, 1–12. <a href="https://doi.org/10.1145/3290605.3300705">https://doi.org/10.1145/3290605.3300705</a>
</div>
<div class="csl-entry" id="ref-feine_taxonomy_2019" role="listitem">
Feine, J., Gnewuch, U., Morana, S., &amp; Maedche, A. (2019). A taxonomy of social cues for conversational agents. <em>International Journal of Human-Computer Studies</em>, <em>132</em>, 138–161. <a href="https://doi.org/10.1016/j.ijhcs.2019.07.009">https://doi.org/10.1016/j.ijhcs.2019.07.009</a>
</div>
<div class="csl-entry" id="ref-friedman_leveraging_2023" role="listitem">
Friedman, L., Ahuja, S., Allen, D., Tan, Z., Sidahmed, H., Long, C., Xie, J., Schubiner, G., Patel, A., Lara, H., Chu, B., Chen, Z., &amp; Tiwari, M. (2023). <em>Leveraging large language models in conversational recommender systems</em> (<span>arXiv</span>:2305.07961). <span>arXiv</span>. <a href="http://arxiv.org/abs/2305.07961">http://arxiv.org/abs/2305.07961</a>
</div>
<div class="csl-entry" id="ref-leveson_improving_2019" role="listitem">
Leveson, N. (2019). <em>Improving the standard risk matrix: Part 1</em>. Department of Aeronautics; Astronautics, <span>MIT</span>.
</div>
<div class="csl-entry" id="ref-mariani_artificial_2023" role="listitem">
Mariani, M. M., Hashemi, N., &amp; Wirtz, J. (2023). Artificial intelligence empowered conversational agents: A systematic literature review and research agenda. <em>Journal of Business Research</em>, <em>161</em>, 113838. <a href="https://doi.org/10.1016/j.jbusres.2023.113838">https://doi.org/10.1016/j.jbusres.2023.113838</a>
</div>
<div class="csl-entry" id="ref-mialon_augmented_2023" role="listitem">
Mialon, G., Dessì, R., Lomeli, M., Nalmpantis, C., Pasunuru, R., Raileanu, R., Rozière, B., Schick, T., Dwivedi-Yu, J., Celikyilmaz, A., Grave, E., LeCun, Y., &amp; Scialom, T. (2023). <em>Augmented language models: A survey</em> (<span>arXiv</span>:2302.07842). <span>arXiv</span>. <a href="https://doi.org/10.48550/arXiv.2302.07842">https://doi.org/10.48550/arXiv.2302.07842</a>
</div>
<div class="csl-entry" id="ref-jokinen_is_2017" role="listitem">
Moore, R. K. (2017). Is spoken language all-or-nothing? Implications for future speech-based human-machine interaction. In K. Jokinen &amp; G. Wilcock (Eds.), <em>Dialogues with social robots</em> (Vol. 427, pp. 281–291). Springer Singapore. <a href="https://doi.org/10.1007/978-981-10-2585-3_22">https://doi.org/10.1007/978-981-10-2585-3_22</a>
</div>
<div class="csl-entry" id="ref-rheu_systematic_2021" role="listitem">
Rheu, M., Shin, J. Y., Peng, W., &amp; Huh-Yoo, J. (2021). Systematic review: Trust-building factors and implications for conversational agent design. <em>International Journal of Human–Computer Interaction</em>, <em>37</em>(1), 81–96. <a href="https://doi.org/10.1080/10447318.2020.1807710">https://doi.org/10.1080/10447318.2020.1807710</a>
</div>
<div class="csl-entry" id="ref-ahlemann_user-specific_2021" role="listitem">
Riefle, L., &amp; Benz, C. (2021). User-specific determinants of conversational agent usage: A review and potential for future research. In F. Ahlemann, R. Schütte, &amp; S. Stieglitz (Eds.), <em>Innovation through information systems</em> (Vol. 47, pp. 115–129). Springer International Publishing. <a href="https://doi.org/10.1007/978-3-030-86797-3_8">https://doi.org/10.1007/978-3-030-86797-3_8</a>
</div>
</div>
</section>
</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        for (let i = 0; i < 2; i++) {
          container.appendChild(note.children[i].cloneNode(true));
        }
        return container.innerHTML
      } else {
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        console.log("RESIZE");
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
</div> <!-- /content -->
<script src="her_files/libs/quarto-html/zenscroll-min.js"></script>
</body></html>