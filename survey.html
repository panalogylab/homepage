<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.156">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Steve J. Bickley, Ho Fai Chan, Bang Dao, Benno Torgler, Son Tran">
<meta name="keywords" content="Social Science, Social AI, Large Language Models, Augmented Language Models, Alignment Research, Survey Method, Experimental Method">

<title>Survey: a platform to explore emerging value perspectives in ALMs’ behaviors</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="survey_files/libs/clipboard/clipboard.min.js"></script>
<script src="survey_files/libs/quarto-html/quarto.js"></script>
<script src="survey_files/libs/quarto-html/popper.min.js"></script>
<script src="survey_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="survey_files/libs/quarto-html/anchor.min.js"></script>
<link href="survey_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="survey_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="survey_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="survey_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="survey_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body>

<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Survey: a platform to explore emerging value perspectives in ALMs’ behaviors</h1>
                      </div>
  </div>
    
  <div class="quarto-title-meta-author">
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-heading">Affiliation</div>
    
      <div class="quarto-title-meta-contents">
      <p class="author"><a href="https://panalogy-lab.com">Steve J. Bickley, Ho Fai Chan, Bang Dao, Benno Torgler, Son Tran</a> </p>
    </div>
      <div class="quarto-title-meta-contents">
          <p class="affiliation">
              Panalogy Lab
            </p>
        </div>
      </div>

  <div class="quarto-title-meta">

        
    
      
    </div>
    
  <div>
    <div class="abstract">
      <div class="abstract-title">Abstract</div>
      <p>This paper presents our work on Survey, a platform for analyzing augmented language models’s (ALMs) emergent alignment behaviours through their attitude and value perspectives.</p>
    </div>
  </div>
  
  </header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-intro" id="toc-sec-intro" class="nav-link active" data-scroll-target="#sec-intro">Motivations</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#platform-design" id="toc-platform-design" class="nav-link" data-scroll-target="#platform-design">Platform Design</a></li>
  <li><a href="#applications" id="toc-applications" class="nav-link" data-scroll-target="#applications">Applications</a></li>
  <li><a href="#future-development" id="toc-future-development" class="nav-link" data-scroll-target="#future-development">Future Development</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="survey_files/survey.pdf" target="_blank"><i class="bi bi-file-pdf"></i>PDF (arxiv)</a></li><li><a href="survey_files/survey.docx"><i class="bi bi-file-word"></i>MS Word</a></li></ul></div></nav>
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="sec-intro" class="level1">
<h1>Motivations</h1>
<p>We built Survey withe following motivations in mind:</p>
<ul>
<li><p>AI alignment in complex social context is <strong>important</strong>, especially when AI systems make decisions or assist people in making decisions in complex settings where there may be no true “right” answer (i.e., where “right” is contextual to the specific information of the real-world situation).</p></li>
<li><p>Doing survey and experiments, despite shortcomings, is still a <strong>widely</strong> adopted method to study social behaviors, including alignments <span class="citation" data-cites="bhattacherjee"><a href="#ref-bhattacherjee" role="doc-biblioref">[1]</a></span>. Language model evaluation frameworks are essentially survey/experiment models <span class="citation" data-cites="openai/e"><a href="#ref-srivastava_beyond_2022" role="doc-biblioref">[3]</a></span>.</p></li>
<li><p>Applying the survey approach to systematically analyzing ALMs’ alignment behaviors is therefore desirable. ALMs are the most advanced AI systems with general reasoning capability, and the have been increasingly operating in complex social context with emergent behaviors not expected before.</p></li>
<li><p>Being able to learn from ALM’s feedback to <strong>improve</strong> survey/experiment design is a great application of ALMs, thus helping researchers to construct quality survey frameworks at a fraction of the resources and time that would be otherwise required when humans have to do everything.</p></li>
<li><p>Survey is the <strong>first</strong> platform delivering robust results for the above value propositions.</p></li>
</ul>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Our new platform, <strong>Survey</strong>, aims to explore emerging value perspectives in Augmented Language Models (ALMs) <span class="citation" data-cites="mialon_augmented_2023"><a href="#ref-mialon_augmented_2023" role="doc-biblioref">[4]</a></span> through decision premises and contextuality in complex social settings. We chose to focus on complex social settings because these environments present a wide array of situations and dilemmas that help in assessing the multifaceted and nuanced value judgments that ALMs have to make in the real world. As a result, we can better understand their decision-making mechanisms and the underlying value systems they rely on.</p>
<p>Our approach to exploring ALM’s behaviors, and their value perspectives, is based on presenting the models with complex sets of survey questions and experimental settings then analyzing their responses under in various contexts. We opted for a survey-based approach as it has been proven to be an effective method for ALM probing and value elicitation <span class="citation" data-cites="arora"><a href="#ref-binz2023" role="doc-biblioref">[6]</a></span>. Value elicitation of humans has always been an important research avenue <span class="citation" data-cites="haerpfer"><a href="#ref-hofstede2005" role="doc-biblioref">[8]</a></span>, as an individual’s identity and values often manifest in the choices and decisions they make. Given the increasing role of ALMs as agents interacting with humans as principals (i.e., principal-agent relationship in nature), it becomes crucial to comprehend the underlying values of these models and their implications for recommendations and decision-making processes, which may or may not align with those of human principals. By allowing the models to respond to a series of contextualized questions, we can gain valuable insights into how they navigate ethical scenarios and prioritize differing values for different principal profiles (e.g., age, race, country of residence, etc).</p>
<p>The first key aspect we address is the question of why understanding ALM’s value perspectives matters in alignment research. By examining the context-dependent values that drive ALMs’ behaviours, we gain valuable insights into the ethical and moral frameworks and traces that shape their decision-making processes (as well as our own). These insights can help us align ALMs with (context-specific) human values and promote responsible AI development <span class="citation" data-cites="tamkin"><a href="#ref-tamkin" role="doc-biblioref">[9]</a></span>.</p>
<p>Defining measures of values is another crucial element of our platform, Survey. We recognize that values are multifaceted and subjective, making their quantification challenging. Through rigorous research and analysis, we aim to develop and translate robust methodologies to define and measure values in the context of ALMs. This will provide a solid foundation for studying and understanding their behavior patterns in complex social settings.</p>
<p>To effectively explore emerging value perspectives in ALMs’ behaviors, we employ state-of-the-art (SOTA) ALM simulation techniques. By simulating ALMs in realistic scenarios, we can observe their decision-making processes and identify any evolving biases or value systems. This knowledge is crucial for staying ahead of potential risks and ensuring the responsible development of AI technologies.</p>
<p>The potential applications of our platform extend beyond the fields of behavioural economics, cognitive psychology, or market research. We envision leveraging the insights gained to help drive social AI alignment and design in research, industry and community alike. By aligning AI systems with human values, we can (co-)create social AI systems that complement and enhance lives, benefiting society as a whole.</p>
<p>In conclusion, our platform Survey offers a unique opportunity to explore and understand the emerging value perspectives in ALMs’ behaviors. By addressing the questions of why world values matter, defining measures of values, and simulating ALMs in complex social settings, we can unlock insights that will help shape the future of AI development. With a focus on social AI alignment and design, we aim to create long-lived, complex social AI agents and systems that align with human values, promoting a responsible and beneficial integration of AI into industry and society.</p>
</section>
<section id="platform-design" class="level1">
<h1>Platform Design</h1>
<p>To be continued…</p>
</section>
<section id="applications" class="level1">
<h1>Applications</h1>
<p>With the emergent capabilities of Large Language Models (LLMs) and the ongoing development of Augmented Language Models (ALMs), understanding the underlying premises that govern their behaviors and decision-making processes becomes increasingly crucial, especially when they operate in complex social settings and have real-world impact. This understanding is essential to ensure the alignment of social AI with human values.</p>
<p>ALMs, which are essentially built on top of pre-trained LLMs like gpt-4, incorporate various elements such as retrieval plug-ins, different learning techniques (few-shot), diverse prompting methods (such as chain-of-thought, self-model, and contextual prompts), functional coding, and integration with other modalities like voice, vision, and sound <span class="citation" data-cites="mialon"><a href="#ref-mialon" role="doc-biblioref">[10]</a></span>. Additionally, future iterations of ALMs are expected to incorporate different AI techniques such as reinforcement learning and symbolic logic, enhancing their knowledge organisation, reasoning, and learning capabilities.</p>
<p>Researchers have been quick to recognize the potential of LLMs as valuable tools to study and probe the human mind and society<span class="citation" data-cites="arora"><a href="#ref-miotto" role="doc-biblioref">[12]</a></span>, given their training on vast amounts of human data and their ability to generate human-like text. Others have discussed their potential in simulating human subjects <span class="citation" data-cites="aher"><a href="#ref-park" role="doc-biblioref">[15]</a></span>. Consequently, researchers from various disciplines such as behavioral economics, cognitive psychology, social psychology, linguistics, and others have proposed different tools, surveys, and methodologies to investigate LLMs’ behavior and decision-making processes. However, the procedures and tuning of LLMs (e.g., temperature, context window, prompt context and structure) for judgment and evaluation of alignment are not yet standardized or consistently applied across studies. Moreover, digital literacy and programming skills continue to present significant obstacles for many researchers, particularly those in behavioral economics and the social sciences.</p>
<p>Considering the fast-paced nature of research and development in AI at the moment, it is essential to also extend our focus beyond pre-trained LLMs and consider the emergent capabilities and value systems of ALMs within various different social contexts. ALMs are increasingly augmented with additional tools and various prompting techniques, spanning different context windows and incorporating other modalities. Furthermore, these ALMs are now actively performing real-world actions. Calling a tool in the context of ALMs often involves having an impact on the virtual or physical world and observing the resulting effects, which are typically integrated into the ALM’s ongoing context. Moreover, ALMs are increasingly engaging in delegate actions such as carrying out transactions on our behalf or responding to customer queries and emails in human-like ways.</p>
<p>By acknowledging the advancements in ALMs and the complex nature of their interactions with the world, we can gain a comprehensive understanding of the premises underlying their behaviors and decision-making processes. This knowledge is crucial for ensuring the development of responsible and aligned social AI systems that reflect human values for the benefit of all humankind.</p>
<p>To facilitate this exploration in an easy and intuitive manner, we have developed a social science research platform called Survey . It empowers researchers to investigate the behaviors and decision-making of LLMs and ALMs in a robust and systematic way, using an easy-to-use, click-and-play online interface. By simulating decision-making across a spectrum of randomised agent demographic attributes (e.g., age, gender, education level, personality, etc), Survey provides a unique platform to investigate even the most sensitive and taboo social science topics (e.g., end-of-life decisions, domestic violence, abortion, etc). By probing these areas in a simulated environment, we leverage the potential of ALMs to explore sensitive topics (e.g., health, social, economic, ethical, etc) in a safe and ethical environment.</p>
</section>
<section id="future-development" class="level1">
<h1>Future Development</h1>
<p>A key limitation of the social context of our simulation is that context is provided in a randomized manner (uniform distribution), and using a generic story template to build up the context of the agent (e.g., you are &lt;AGE&gt;, your personality is &lt;BIG 5 PROFILE&gt;, and reside in &lt;LOCATION&gt;). We do not draw on or attempt to simulate human subjects from demographic backgrounds of past survey respondents, as in e.g., <span class="citation" data-cites="argyle"><a href="#ref-argyle" role="doc-biblioref">[16]</a></span>. Note, this approach also means that sometimes we end up with “interesting” agent profile combinations that may seldom present in the real world (e.g., a male lesbian).</p>
<p>As an initial proof-of-concept, we have naturally had to limit the number of context variables available in the Survey platform. A key next step is to allow the addition and customization of top-level profile attributes as well as their options (i.e., an extension to the existing capability for customising options within the existing set of top-level demographic attributes like age, gender, etc.). For example, to create new top-level attributes like employment status, rural vs urban residence, mental health status, occupational industry, marital/family status, etc.</p>
<p>Other future development in the pipeline for the Survey platform:</p>
<ul>
<li><p>Customisation of the “analysis” parameter/prompt to allow users to directly enter the prompt instructions to customise how the ALMs critically analyse the questions in “critic” mode.</p></li>
<li><p>Parallelisation of OpenAI API queries to reduce simulation times.</p></li>
<li><p>User interface - add more detailed progress indicator, add output visualisation</p></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
<section id="references" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body" role="list">
<div id="ref-bhattacherjee" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">A. Bhattacherjee, <span>“Social Science Research: Principles, Methods, and Practices.”</span></div>
</div>
<div id="ref-openai/e" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline"><span>“Openai/evals: Evals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks.”</span> Available: <a href="https://github.com/openai/evals">https://github.com/openai/evals</a></div>
</div>
<div id="ref-srivastava_beyond_2022" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">A. Srivastava <em>et al.</em>, <span>“Beyond the <span>Imitation</span> <span>Game</span>: <span>Quantifying</span> and extrapolating the capabilities of language models.”</span> arXiv, Jun. 2022. doi: <a href="https://doi.org/10.48550/arXiv.2206.04615">10.48550/arXiv.2206.04615</a>.</div>
</div>
<div id="ref-mialon_augmented_2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">G. Mialon <em>et al.</em>, <span>“Augmented <span>Language</span> <span>Models</span>: A <span>Survey</span>.”</span> arXiv, Feb. 2023. doi: <a href="https://doi.org/10.48550/arXiv.2302.07842">10.48550/arXiv.2302.07842</a>.</div>
</div>
<div id="ref-arora" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">A. Arora, L.-A. Kaffee, and I. Augenstein, <span>“Probing Pre-Trained Language Models for Cross-Cultural Differences in Values.”</span></div>
</div>
<div id="ref-binz2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">M. Binz and E. Schulz, <span>“Using cognitive psychology to understand GPT-3,”</span> <em>Proceedings of the National Academy of Sciences</em>, vol. 120, no. 6, p. e2218523120, Feb. 2023, doi: <a href="https://doi.org/10.1073/pnas.2218523120">10.1073/pnas.2218523120</a>.</div>
</div>
<div id="ref-haerpfer" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">C. Haerpfer, R. Inglehart, A. Moreno, C. Welzel, K. Kizilova, and J. Diez-Medrano, <span>“World values survey: Round seven<span></span>country-pooled datafile.”</span> </div>
</div>
<div id="ref-hofstede2005" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">G. Hofstede, <span>“Culture<span>’</span>s recent consequences.”</span> Product &amp; Systems Internationalisation, Inc., 2005. Available: <a href="https://3-4">3-4</a></div>
</div>
<div id="ref-tamkin" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">A. Tamkin, M. Brundage, J. Clark, and D. Ganguli, <span>“Understanding the capabilities, limitations, and societal impact of large language models,”</span> doi: <a href="https://doi.org/10.48550/arXiv.2102.02503">10.48550/arXiv.2102.02503</a>.</div>
</div>
<div id="ref-mialon" class="csl-entry" role="listitem">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">G. Mialon <em>et al.</em>, <span>“Augmented Language Models: a Survey.”</span></div>
</div>
<div id="ref-korinek2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">A. Korinek, <span>“Language Models and Cognitive Automation for Economic Research,”</span> 2023.</div>
</div>
<div id="ref-miotto" class="csl-entry" role="listitem">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">M. Miotto, N. Rossberg, and B. Kleinberg, <span>“Who is GPT-3? An Exploration of Personality, Values and Demographics.”</span></div>
</div>
<div id="ref-aher" class="csl-entry" role="listitem">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">G. Aher, R. I. Arriaga, and A. T. Kalai, <span>“Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies.”</span></div>
</div>
<div id="ref-horton" class="csl-entry" role="listitem">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">J. J. Horton, <span>“Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?”</span></div>
</div>
<div id="ref-park" class="csl-entry" role="listitem">
<div class="csl-left-margin">[15] </div><div class="csl-right-inline">J. S. Park, L. Popowski, C. J. Cai, M. R. Morris, P. Liang, and M. S. Bernstein, <span>“Social Simulacra: Creating Populated Prototypes for Social Computing Systems.”</span></div>
</div>
<div id="ref-argyle" class="csl-entry" role="listitem">
<div class="csl-left-margin">[16] </div><div class="csl-right-inline">L. P. Argyle <em>et al.</em>, <span>“AI Chat Assistants can Improve Conversations about Divisive Topics.”</span></div>
</div>
</div>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    if (id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        for (let i = 0; i < 2; i++) {
          container.appendChild(note.children[i].cloneNode(true));
        }
        return container.innerHTML
      } else {
        return note.innerHTML;
      }
    } else {
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      try { hash = new URL(url).hash; } catch {}
      const id = hash.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note !== null) {
        try {
          const html = processXRef(id, note);
          instance.setContent(html);
        } finally {
          instance.enable();
          instance.show();
        }
      } else {
        // See if we can fetch this
        fetch(url.split('#')[0])
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.getElementById(id);
          if (note !== null) {
            const html = processXRef(id, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>